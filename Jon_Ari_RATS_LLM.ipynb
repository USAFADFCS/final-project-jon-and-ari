{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a9b13b",
   "metadata": {},
   "source": [
    "# Agentic Model: RATS AI Triage Classifier\n",
    "\n",
    "Combat Triage AI - Complete Implementation with Quantization and SALT Protocol\n",
    "\n",
    "Ready for Raspberry Pi Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603449cd",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1b162",
   "metadata": {},
   "source": [
    "#### Step 1A: Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (4.55.4)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (2025.6.15)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
      "\u001b[2K  Attempting uninstall: transformers\n",
      "\u001b[2K    Found existing installation: transformers 4.55.4\n",
      "\u001b[2K    Uninstalling transformers-4.55.4:‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.55.4‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "optimum-onnx 0.0.3 requires transformers<4.56.0,>=4.36.0, but you have transformers 4.57.1 which is incompatible.\n",
      "fair-llm 0.1.0 requires huggingface-hub==0.33.0, but you have huggingface-hub 0.35.3 which is incompatible.\n",
      "fair-llm 0.1.0 requires tokenizers==0.21.1, but you have tokenizers 0.22.1 which is incompatible.\n",
      "fair-llm 0.1.0 requires transformers==4.52.4, but you have transformers 4.57.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.22.1 transformers-4.57.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: optimum[onnxruntime] in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.29 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (2.7.1)\n",
      "Requirement already satisfied: packaging in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (25.0)\n",
      "Requirement already satisfied: numpy in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (2.3.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.8.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (0.35.3)\n",
      "Requirement already satisfied: optimum-onnx[onnxruntime] in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (0.0.3)\n",
      "Requirement already satisfied: filelock in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (1.1.4)\n",
      "Requirement already satisfied: setuptools in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11->optimum[onnxruntime]) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers>=4.29->optimum[onnxruntime]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers>=4.29->optimum[onnxruntime]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers>=4.29->optimum[onnxruntime]) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (3.0.2)\n",
      "Collecting transformers>=4.29 (from optimum[onnxruntime])\n",
      "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: onnx in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (1.19.1)\n",
      "Requirement already satisfied: onnxruntime>=1.18.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (1.22.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.29->optimum[onnxruntime])\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: coloredlogs in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (5.29.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (10.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnx->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.6.15)\n",
      "Using cached transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: transformers‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.12m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.57.1:‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.1‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fair-llm 0.1.0 requires huggingface-hub==0.33.0, but you have huggingface-hub 0.35.3 which is incompatible.\n",
      "fair-llm 0.1.0 requires tokenizers==0.21.1, but you have tokenizers 0.21.4 which is incompatible.\n",
      "fair-llm 0.1.0 requires transformers==4.52.4, but you have transformers 4.55.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.4 transformers-4.55.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchaudio in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from gtts) (2.32.4)\n",
      "Collecting click<8.2,>=7.1 (from gtts)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->gtts) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests<3,>=2.27->gtts) (2025.6.15)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: click, gtts\n",
      "\u001b[2K  Attempting uninstall: click\n",
      "\u001b[2K    Found existing installation: click 8.2.1\n",
      "\u001b[2K    Uninstalling click-8.2.1:\n",
      "\u001b[2K      Successfully uninstalled click-8.2.1\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [gtts]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fair-llm 0.1.0 requires click==8.2.1, but you have click 8.1.8 which is incompatible.\n",
      "fair-llm 0.1.0 requires huggingface-hub==0.33.0, but you have huggingface-hub 0.35.3 which is incompatible.\n",
      "fair-llm 0.1.0 requires tokenizers==0.21.1, but you have tokenizers 0.21.4 which is incompatible.\n",
      "fair-llm 0.1.0 requires transformers==4.52.4, but you have transformers 4.55.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed click-8.1.8 gtts-2.5.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install optimum[onnxruntime]\n",
    "!pip install torch torchaudio\n",
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5045455",
   "metadata": {},
   "source": [
    "#### Step 1B: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, torchaudio, re, time, pyttsx3\n",
    "import numpy as np\n",
    "from transformers import pipeline, WhisperForConditionalGeneration, AutoProcessor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0c033",
   "metadata": {},
   "source": [
    "#### Step 1C: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0be3b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"openai/whisper-tiny.en\"\n",
    "DEVICE = \"cpu\"  # Pi doesn't have GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724ed9a",
   "metadata": {},
   "source": [
    "Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e95d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def generate_triage_audio(result, output_dir=\"triage_audio\"):\n",
    "    \"\"\"\n",
    "    Generate audio file from triage results using offline TTS\n",
    "    \n",
    "    Args:\n",
    "        result: Dictionary containing triage assessment results\n",
    "        output_dir: Directory to save audio files\n",
    "        \n",
    "    Returns:\n",
    "        Path to generated audio file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize offline TTS engine\n",
    "    engine = pyttsx3.init()\n",
    "    \n",
    "    # Configure voice properties (optional)\n",
    "    engine.setProperty('rate', 150)    # Speed of speech\n",
    "    engine.setProperty('volume', 0.9)  # Volume (0.0 to 1.0)\n",
    "    \n",
    "    # Build the spoken message\n",
    "    message_parts = []\n",
    "    \n",
    "    # Triage category announcement\n",
    "    category = result['triage_category']\n",
    "    message_parts.append(f\"Triage category: {category}.\")\n",
    "    \n",
    "    # Add urgency based on category\n",
    "    if category == \"Immediate\":\n",
    "        message_parts.append(\"This patient requires immediate medical attention.\")\n",
    "    elif category == \"Delayed\":\n",
    "        message_parts.append(\"This patient has serious injuries but can wait for treatment.\")\n",
    "    elif category == \"Minimal\":\n",
    "        message_parts.append(\"This patient has minor injuries.\")\n",
    "    elif category == \"Expectant\":\n",
    "        message_parts.append(\"This patient has injuries incompatible with life.\")\n",
    "    elif category == \"Unknown\":\n",
    "        message_parts.append(\"Additional assessment data needed.\")\n",
    "    \n",
    "    # Confidence level\n",
    "    confidence_pct = int(result['confidence'] * 100)\n",
    "    message_parts.append(f\"Assessment confidence: {confidence_pct} percent.\")\n",
    "    \n",
    "    # Key findings\n",
    "    entities = result['entities']\n",
    "    findings = []\n",
    "    \n",
    "    if entities.get('can_walk') is not None:\n",
    "        findings.append(f\"Patient {'can' if entities['can_walk'] else 'cannot'} walk\")\n",
    "    \n",
    "    if entities.get('bleeding_severe'):\n",
    "        findings.append(\"Severe bleeding detected\")\n",
    "    \n",
    "    if entities.get('resp_rate') is not None:\n",
    "        findings.append(f\"Respiratory rate: {entities['resp_rate']} per minute\")\n",
    "    \n",
    "    if entities.get('obeys_commands') is not None:\n",
    "        findings.append(f\"Patient {'obeys' if entities['obeys_commands'] else 'does not obey'} commands\")\n",
    "    \n",
    "    if findings:\n",
    "        message_parts.append(\"Key findings: \" + \", \".join(findings) + \".\")\n",
    "    \n",
    "    # Next question\n",
    "    if result['next_question']:\n",
    "        message_parts.append(f\"Recommended next question: {result['next_question']}\")\n",
    "    \n",
    "    # Combine all parts\n",
    "    full_message = \" \".join(message_parts)\n",
    "    \n",
    "    # Generate audio\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    patient_id = result['patient_id'].replace('.mp3', '').replace(' ', '_')\n",
    "    output_filename = f\"{output_dir}/triage_{patient_id}_{timestamp}.wav\"\n",
    "    \n",
    "    print(f\"\\nüîä Generating audio file...\")\n",
    "    print(f\"üìù Message: {full_message}\")\n",
    "    \n",
    "    # Save to file\n",
    "    engine.save_to_file(full_message, output_filename)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "    print(f\"‚úì Audio saved to: {output_filename}\")\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "def generate_quick_alert_audio(category, output_dir=\"triage_audio\"):\n",
    "    \"\"\"\n",
    "    Generate quick alert audio for immediate triage category using offline TTS\n",
    "    \n",
    "    Args:\n",
    "        category: Triage category\n",
    "        output_dir: Directory to save audio files\n",
    "        \n",
    "    Returns:\n",
    "        Path to generated audio file\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize offline TTS engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 175)    # Faster for alerts\n",
    "    engine.setProperty('volume', 1.0)  # Maximum volume for alerts\n",
    "    \n",
    "    alert_messages = {\n",
    "        \"Immediate\": \"Alert! Immediate medical attention required!\",\n",
    "        \"Delayed\": \"Attention. Delayed category patient.\",\n",
    "        \"Minimal\": \"Minimal injuries detected.\",\n",
    "        \"Expectant\": \"Expectant category.\",\n",
    "        \"Unknown\": \"Assessment incomplete.\"\n",
    "    }\n",
    "    \n",
    "    message = alert_messages.get(category, \"Triage assessment complete.\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"{output_dir}/alert_{category}_{timestamp}.wav\"\n",
    "    \n",
    "    engine.save_to_file(message, output_filename)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "    print(f\"‚úì Alert audio saved to: {output_filename}\")\n",
    "    \n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767eadc6",
   "metadata": {},
   "source": [
    "## Step 2: Medical Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0360e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded combat medical vocabulary\n",
    "COMBAT_MEDICAL_LEXICON = \"\"\"\n",
    "tourniquet, hemorrhage, massive hemorrhage, capillary refill, \n",
    "obey commands, airway patent, airway obstructed, \n",
    "respirations per minute, respiratory rate, breathing adequately,\n",
    "radial pulse present, radial pulse absent, carotid pulse,\n",
    "shock, hypotensive, pale, clammy, cold,\n",
    "GSW, gunshot wound, blast injury, shrapnel, amputation,\n",
    "conscious, unconscious, alert, verbal, pain, unresponsive,\n",
    "chest seal, needle decompression, nasopharyngeal airway,\n",
    "combat gauze, hemostatic agent, pressure dressing,\n",
    "walking wounded, litter urgent, urgent surgical,\n",
    "can walk, cannot walk, ambulatory, unable to walk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b152e",
   "metadata": {},
   "source": [
    "## Step 3: Model Quantization\n",
    "\n",
    "Useful for the rasberry pi on our drone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "739a2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and quantizing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and quantized successfully\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ========== MODEL LOADING WITH QUANTIZATION ==========\n",
    "print(\"Loading and quantizing model...\")\n",
    "\n",
    "# Load model and processor separately\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID)\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Quantize the model (makes it 4x smaller and faster)\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, \n",
    "    {torch.nn.Linear},  # Quantize linear layers\n",
    "    dtype=torch.qint8   # Use 8-bit integers\n",
    ")\n",
    "\n",
    "# Create ASR pipeline with quantized model AND processor components\n",
    "asr = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=quantized_model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    device=DEVICE,\n",
    "    chunk_length_s=30,\n",
    "    stride_length_s=5,\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "print(f\"Model loaded and quantized successfully\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ee3c9",
   "metadata": {},
   "source": [
    "### Step 3: Audio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4342fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combat_audio(audio_path):\n",
    "    \"\"\"Handle noisy battlefield audio conditions\"\"\"\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Resample to 16kHz (Whisper requirement)\n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "    \n",
    "    # Noise reduction - high-pass filter for wind/vehicle noise\n",
    "    wav = torchaudio.functional.highpass_biquad(wav, 16000, cutoff_freq=200)\n",
    "    \n",
    "    # Normalize volume (gunfire may cause clipping)\n",
    "    max_val = wav.abs().max()\n",
    "    if max_val > 0:\n",
    "        wav = wav / max_val\n",
    "    \n",
    "    return wav, 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "859fecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_vad_chunks(wav_path, min_speech_len=0.6):\n",
    "    \"\"\"Voice Activity Detection - remove silence\"\"\"\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    \n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "    \n",
    "    # Simple energy-based VAD\n",
    "    energy = wav.pow(2).mean(dim=0)\n",
    "    threshold = energy.mean() * 0.3\n",
    "    \n",
    "    voiced_mask = energy > threshold\n",
    "    if voiced_mask.sum() < 16000 * min_speech_len:\n",
    "        return [wav_path]  # Too short, return original\n",
    "    \n",
    "    # For simplicity, return original if has enough speech\n",
    "    return [wav_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94ea1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TRANSCRIPTION ==========\n",
    "def transcribe(path: str) -> dict:\n",
    "    \"\"\"Transcribe audio with medical vocabulary priming\"\"\"\n",
    "    \n",
    "    # Build prompt for medical context\n",
    "    prompt_ids = processor.get_prompt_ids(text=COMBAT_MEDICAL_LEXICON)\n",
    "    \n",
    "    if isinstance(prompt_ids, np.ndarray):\n",
    "        prompt_ids = prompt_ids.tolist()\n",
    "    elif isinstance(prompt_ids, tuple):\n",
    "        prompt_ids = list(prompt_ids)\n",
    "    \n",
    "    prompt_ids = torch.tensor(prompt_ids, dtype=torch.long, device=DEVICE)\n",
    "    \n",
    "    # Clear any old forced decoder IDs\n",
    "    try:\n",
    "        asr.model.generation_config.forced_decoder_ids = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    result = asr(\n",
    "        path,\n",
    "        generate_kwargs={\n",
    "            \"prompt_ids\": prompt_ids,\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_beams\": 5,\n",
    "            \"do_sample\": False,\n",
    "        },\n",
    "        return_timestamps=True\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def transcribe_with_vad(path):\n",
    "    \"\"\"Transcribe with voice activity detection\"\"\"\n",
    "    out = {\"text\": \"\", \"chunks\": []}\n",
    "    \n",
    "    for chunk in simple_vad_chunks(path):\n",
    "        r = transcribe(chunk)\n",
    "        out[\"text\"] += (\" \" + r[\"text\"]).strip()\n",
    "        if \"chunks\" in r:\n",
    "            out[\"chunks\"].extend(r[\"chunks\"])\n",
    "    \n",
    "    return out\n",
    "\n",
    "# ========== ENTITY EXTRACTION ==========\n",
    "def extract_triage_entities(transcription_text):\n",
    "    \"\"\"Extract SALT-relevant medical information from transcription\"\"\"\n",
    "    text_lower = transcription_text.lower()\n",
    "    \n",
    "    entities = {\n",
    "        \"can_walk\": None,\n",
    "        \"bleeding_severe\": False,\n",
    "        \"obeys_commands\": None,\n",
    "        \"resp_rate\": None,\n",
    "        \"radial_pulse\": None,\n",
    "        \"mental_status\": None,\n",
    "        \"cap_refill_sec\": None\n",
    "    }\n",
    "    \n",
    "    evidence = []\n",
    "    \n",
    "    \n",
    "    # Walking ability\n",
    "    walk_yes = [\"can walk\", \"walking\", \"ambulatory\", \"able to walk\"]\n",
    "    walk_no = [\"cannot walk\", \"can't walk\", \"unable to walk\", \"not walking\"]\n",
    "    \n",
    "    for phrase in walk_yes:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"can_walk\"] = True\n",
    "            evidence.append(f\"Walking: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    for phrase in walk_no:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"can_walk\"] = False\n",
    "            evidence.append(f\"Not walking: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Severe bleeding\n",
    "    bleeding_phrases = [\"severe bleeding\", \"hemorrhage\", \"massive hemorrhage\", \n",
    "                       \"tourniquet applied\", \"massive bleeding\", \"heavy bleeding\"]\n",
    "    for phrase in bleeding_phrases:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"bleeding_severe\"] = True\n",
    "            evidence.append(f\"Severe bleeding: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Command response\n",
    "    obey_yes = [\"obeys commands\", \"follows commands\", \"responsive to commands\", \"responding\"]\n",
    "    obey_no = [\"does not obey\", \"doesn't obey\", \"unresponsive\", \"no response\", \n",
    "               \"not responding\", \"not obeying\"]\n",
    "    \n",
    "    for phrase in obey_yes:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"obeys_commands\"] = True\n",
    "            evidence.append(f\"Obeys commands: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    for phrase in obey_no:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"obeys_commands\"] = False\n",
    "            evidence.append(f\"Does not obey: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Respiratory rate extraction\n",
    "    resp_patterns = [\n",
    "        r'(\\d+)\\s*breaths?\\s*(?:per\\s*minute)?',\n",
    "        r'(\\d+)\\s*respirations?\\s*(?:per\\s*minute)?',\n",
    "        r'respiratory\\s*rate\\s*(?:of\\s*)?(\\d+)',\n",
    "        r'breathing\\s*(?:at\\s*)?(\\d+)',\n",
    "        r'(\\d+)\\s*rpm'\n",
    "    ]\n",
    "    \n",
    "    for pattern in resp_patterns:\n",
    "        match = re.search(pattern, text_lower)\n",
    "        if match:\n",
    "            entities[\"resp_rate\"] = int(match.group(1))\n",
    "            evidence.append(f\"Respiratory rate: {match.group(1)} detected\")\n",
    "            break\n",
    "    \n",
    "    # Radial pulse\n",
    "    pulse_yes = [\"radial pulse present\", \"has radial pulse\", \"pulse present\"]\n",
    "    pulse_no = [\"no radial pulse\", \"radial pulse absent\", \"no pulse\"]\n",
    "    \n",
    "    for phrase in pulse_yes:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"radial_pulse\"] = True\n",
    "            evidence.append(f\"Radial pulse: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    for phrase in pulse_no:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"radial_pulse\"] = False\n",
    "            evidence.append(f\"No radial pulse: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Mental status\n",
    "    if \"alert\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"alert\"\n",
    "        evidence.append(\"Mental status: alert\")\n",
    "    elif \"verbal\" in text_lower or \"responds to verbal\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"verbal\"\n",
    "        evidence.append(\"Mental status: verbal\")\n",
    "    elif \"pain\" in text_lower or \"responds to pain\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"pain\"\n",
    "        evidence.append(\"Mental status: pain\")\n",
    "    elif \"unresponsive\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"unresponsive\"\n",
    "        evidence.append(\"Mental status: unresponsive\")\n",
    "    \n",
    "    return entities, evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d27d05e",
   "metadata": {},
   "source": [
    "## Step 5: Implement SALT Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a22e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SALT TRIAGE RULES ==========\n",
    "def salt_rules(entities, sensors=None):\n",
    "    \"\"\"\n",
    "    Implement SALT (Sort, Assess, Lifesaving interventions, Treatment/Transport) triage\n",
    "    \n",
    "    Categories:\n",
    "    - Immediate (Red): Life-threatening injuries, needs immediate care\n",
    "    - Delayed (Yellow): Serious injuries, can wait for treatment\n",
    "    - Minimal (Green): Minor injuries, walking wounded\n",
    "    - Expectant (Black): Injuries incompatible with life\n",
    "    \"\"\"\n",
    "    s = sensors or {}\n",
    "    \n",
    "    # Merge sensor data\n",
    "    can_walk = entities.get(\"can_walk\") or s.get(\"can_walk\")\n",
    "    severe_bleed = entities.get(\"bleeding_severe\") or s.get(\"bleeding_detected\")\n",
    "    resp = entities.get(\"resp_rate\") or s.get(\"resp_rate\")\n",
    "    obeys = entities.get(\"obeys_commands\") or s.get(\"obeys_commands\")\n",
    "    radial_pulse = entities.get(\"radial_pulse\") or s.get(\"radial_pulse\")\n",
    "    \n",
    "    # SALT Algorithm\n",
    "    # Step 1: Can the patient walk?\n",
    "    if can_walk is True:\n",
    "        return \"Minimal\"\n",
    "    \n",
    "    # Step 2: Assess for life-threatening bleeding\n",
    "    if severe_bleed:\n",
    "        return \"Immediate\"\n",
    "    \n",
    "    # Step 3: Check respirations\n",
    "    if resp is None:\n",
    "        return \"Unknown\"  # Need more data\n",
    "    \n",
    "    if resp == 0:\n",
    "        return \"Expectant\"  # Not breathing\n",
    "    \n",
    "    if resp >= 30:\n",
    "        return \"Immediate\"  # Respiratory distress\n",
    "    \n",
    "    # Step 4: Check mental status / obeys commands\n",
    "    if obeys is False:\n",
    "        return \"Immediate\"  # Altered mental status\n",
    "    \n",
    "    # Step 5: Check radial pulse (perfusion)\n",
    "    if radial_pulse is False:\n",
    "        return \"Immediate\"  # Poor perfusion\n",
    "    \n",
    "    # Default: injuries present but stable\n",
    "    return \"Delayed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67ddc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIDENCE & NEXT QUESTION ==========\n",
    "def calculate_confidence(entities):\n",
    "    \"\"\"Calculate confidence based on how much data we have\"\"\"\n",
    "    total_fields = len(entities)\n",
    "    filled_fields = sum(1 for v in entities.values() if v is not None and v is not False)\n",
    "    return filled_fields / total_fields\n",
    "\n",
    "def suggest_next_question(entities):\n",
    "    \"\"\"Ask medic for missing critical SALT info\"\"\"\n",
    "    \n",
    "    if entities[\"can_walk\"] is None:\n",
    "        return \"Can the patient walk?\"\n",
    "    \n",
    "    if not entities[\"bleeding_severe\"] and entities.get(\"bleeding_severe\") is None:\n",
    "        return \"Is there severe bleeding or hemorrhage?\"\n",
    "    \n",
    "    if entities[\"resp_rate\"] is None:\n",
    "        return \"What is the respiratory rate per minute?\"\n",
    "    \n",
    "    if entities[\"obeys_commands\"] is None:\n",
    "        return \"Does the patient obey commands?\"\n",
    "    \n",
    "    if entities[\"radial_pulse\"] is None:\n",
    "        return \"Is there a radial pulse present?\"\n",
    "    \n",
    "    return None  # All critical data collected\n",
    "\n",
    "# ========== SENSOR FUSION ==========\n",
    "def fuse_sensor_data(audio_entities, drone_sensors):\n",
    "    \"\"\"Combine voice transcription with drone sensor data\"\"\"\n",
    "    final_entities = audio_entities.copy()\n",
    "    \n",
    "    # Sensor data overrides uncertain voice data\n",
    "    if drone_sensors.get(\"thermal_bleeding_detected\") is not None:\n",
    "        if audio_entities[\"bleeding_severe\"] is None or not audio_entities[\"bleeding_severe\"]:\n",
    "            final_entities[\"bleeding_severe\"] = drone_sensors[\"thermal_bleeding_detected\"]\n",
    "    \n",
    "    if drone_sensors.get(\"movement_detected\") is not None:\n",
    "        if audio_entities[\"can_walk\"] is None:\n",
    "            final_entities[\"can_walk\"] = drone_sensors[\"movement_detected\"]\n",
    "    \n",
    "    if drone_sensors.get(\"heart_rate\") is not None:\n",
    "        # Estimate respiratory rate from heart rate if not available\n",
    "        if audio_entities[\"resp_rate\"] is None:\n",
    "            # Rough estimate: normal resp is ~1/4 of heart rate\n",
    "            final_entities[\"resp_rate\"] = int(drone_sensors[\"heart_rate\"] / 4)\n",
    "    \n",
    "    return final_entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af81fc",
   "metadata": {},
   "source": [
    "## Step 6: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca6bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_patient(audio_path, sensor_data=None, generate_audio=True):\n",
    "    \"\"\"\n",
    "    Complete combat triage pipeline with optional audio output\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to audio file of medic assessment\n",
    "        sensor_data: Optional dict of drone sensor readings\n",
    "        generate_audio: Whether to generate audio output (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        Full triage assessment with category and confidence\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRIAGE ASSESSMENT INITIATED\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Step 1: Transcribe audio\n",
    "    print(\"üìù Transcribing audio...\")\n",
    "    transcription = transcribe_with_vad(audio_path)\n",
    "    print(f\"‚úì Transcription: {transcription['text'][:100]}...\")\n",
    "    \n",
    "    # Step 2: Extract medical entities\n",
    "    print(\"\\nüîç Extracting medical information...\")\n",
    "    entities, evidence = extract_triage_entities(transcription[\"text\"])\n",
    "    \n",
    "    # Step 3: Fuse with sensor data if available\n",
    "    if sensor_data:\n",
    "        print(\"ü§ñ Fusing with sensor data...\")\n",
    "        entities = fuse_sensor_data(entities, sensor_data)\n",
    "    \n",
    "    # Step 4: Apply SALT triage rules\n",
    "    print(\"\\nüè• Applying SALT triage protocol...\")\n",
    "    triage_category = salt_rules(entities, sensor_data)\n",
    "    \n",
    "    # Step 5: Calculate confidence and suggest next question\n",
    "    confidence = calculate_confidence(entities)\n",
    "    next_question = suggest_next_question(entities)\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Format results\n",
    "    result = {\n",
    "        \"patient_id\": os.path.basename(audio_path),\n",
    "        \"transcription\": transcription[\"text\"],\n",
    "        \"entities\": entities,\n",
    "        \"evidence\": evidence,\n",
    "        \"triage_category\": triage_category,\n",
    "        \"confidence\": confidence,\n",
    "        \"next_question\": next_question,\n",
    "        \"processing_time_sec\": round(processing_time, 2),\n",
    "        \"timestamp\": transcription.get(\"chunks\", [])\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRIAGE RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üöë Category: {triage_category}\")\n",
    "    print(f\"üìä Confidence: {confidence*100:.0f}%\")\n",
    "    print(f\"‚è±Ô∏è  Processing Time: {processing_time:.2f}s\")\n",
    "    print(f\"\\nüìã Extracted Information:\")\n",
    "    for key, value in entities.items():\n",
    "        if value is not None:\n",
    "            print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "    \n",
    "    if next_question:\n",
    "        print(f\"\\n‚ùì Recommended Question: {next_question}\")\n",
    "    \n",
    "    if evidence:\n",
    "        print(f\"\\nüìù Evidence:\")\n",
    "        for item in evidence:\n",
    "            print(f\"  ‚Ä¢ {item}\")\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # NEW: Generate audio output\n",
    "    if generate_audio:\n",
    "        audio_file = generate_triage_audio(result)\n",
    "        result['audio_output'] = audio_file\n",
    "        \n",
    "        # Generate quick alert for immediate cases\n",
    "        if triage_category == \"Immediate\":\n",
    "            alert_file = generate_quick_alert_audio(triage_category)\n",
    "            result['alert_audio'] = alert_file\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f61c8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 1: Audio transcription with audio output\n",
      "\n",
      "============================================================\n",
      "TRIAGE ASSESSMENT INITIATED\n",
      "============================================================\n",
      "\n",
      "üìù Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Transcription: Ow, my leg hurts, and I can't breathe....\n",
      "\n",
      "üîç Extracting medical information...\n",
      "\n",
      "üè• Applying SALT triage protocol...\n",
      "\n",
      "============================================================\n",
      "TRIAGE RESULTS\n",
      "============================================================\n",
      "üöë Category: Unknown\n",
      "üìä Confidence: 0%\n",
      "‚è±Ô∏è  Processing Time: 4.45s\n",
      "\n",
      "üìã Extracted Information:\n",
      "  ‚Ä¢ bleeding_severe: False\n",
      "\n",
      "‚ùì Recommended Question: Can the patient walk?\n",
      "============================================================\n",
      "\n",
      "\n",
      "üîä Generating audio file...\n",
      "üìù Message: Triage category: Unknown. Assessment confidence: 0 percent. Recommended next question: Can the patient walk?\n"
     ]
    },
    {
     "ename": "gTTSError",
     "evalue": "Failed to connect. Probable cause: Unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteDisconnected\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/http/client.py:300\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRemoteDisconnected\u001b[39m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/util/retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/util/util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/http/client.py:300\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/gtts/tts.py:268\u001b[39m, in \u001b[36mgTTS.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m requests.Session() \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     r = \u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetproxies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mheaders-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, idx, r.request.headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/requests/adapters.py:682\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mgTTSError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test with audio generation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTEST 1: Audio transcription with audio output\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result1 = \u001b[43mtriage_patient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAUDIO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_audio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTEST 2: Audio + sensor fusion with audio output\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m mock_sensor_data = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mthermal_bleeding_detected\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmovement_detected\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mheart_rate\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m120\u001b[39m\n\u001b[32m     10\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mtriage_patient\u001b[39m\u001b[34m(audio_path, sensor_data, generate_audio)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# NEW: Generate audio output\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m generate_audio:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     audio_file = \u001b[43mgenerate_triage_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     result[\u001b[33m'\u001b[39m\u001b[33maudio_output\u001b[39m\u001b[33m'\u001b[39m] = audio_file\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# Generate quick alert for immediate cases\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mgenerate_triage_audio\u001b[39m\u001b[34m(result, output_dir)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìù Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m tts = gTTS(text=full_message, lang=\u001b[33m'\u001b[39m\u001b[33men\u001b[39m\u001b[33m'\u001b[39m, slow=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mtts\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Audio saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/gtts/tts.py:335\u001b[39m, in \u001b[36mgTTS.save\u001b[39m\u001b[34m(self, savefile)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Do the TTS API request and write result to file.\u001b[39;00m\n\u001b[32m    326\u001b[39m \n\u001b[32m    327\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    332\u001b[39m \n\u001b[32m    333\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(savefile), \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_to_fp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     f.flush()\n\u001b[32m    337\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mSaved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, savefile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/gtts/tts.py:316\u001b[39m, in \u001b[36mgTTS.write_to_fp\u001b[39m\u001b[34m(self, fp)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Do the TTS API request(s) and write bytes to a file-like object.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m    306\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m \n\u001b[32m    313\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpart-\u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[33;43m written to \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/gtts/tts.py:287\u001b[39m, in \u001b[36mgTTS.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;66;03m# Request failed\u001b[39;00m\n\u001b[32m    286\u001b[39m     log.debug(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m gTTSError(tts=\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Write\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.iter_lines(chunk_size=\u001b[32m1024\u001b[39m):\n",
      "\u001b[31mgTTSError\u001b[39m: Failed to connect. Probable cause: Unknown"
     ]
    }
   ],
   "source": [
    "# Test with audio generation\n",
    "print(\"TEST 1: Audio transcription with audio output\")\n",
    "result1 = triage_patient(AUDIO, generate_audio=True)\n",
    "\n",
    "print(\"\\n\\nTEST 2: Audio + sensor fusion with audio output\")\n",
    "mock_sensor_data = {\n",
    "    \"thermal_bleeding_detected\": False,\n",
    "    \"movement_detected\": False,\n",
    "    \"heart_rate\": 120\n",
    "}\n",
    "result2 = triage_patient(AUDIO, sensor_data=mock_sensor_data, generate_audio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece06fb",
   "metadata": {},
   "source": [
    "## Step 7: Performance metrics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88117c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE METRICS\n",
      "============================================================\n",
      "Model: openai/whisper-tiny.en\n",
      "Quantized: Yes (8-bit)\n",
      "Device: cpu\n",
      "Model parameters: 21.2M\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== PERFORMANCE METRICS ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"Quantized: Yes (8-bit)\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in asr.model.parameters()) / 1e6:.1f}M\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
