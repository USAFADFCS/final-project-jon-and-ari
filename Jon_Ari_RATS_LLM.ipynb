{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a9b13b",
   "metadata": {},
   "source": [
    "# Agentic Model: RATS AI Triage Classifier\n",
    "\n",
    "Combat Triage AI - Complete Implementation with Quantization and SALT Protocol\n",
    "\n",
    "Ready for Raspberry Pi Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603449cd",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1b162",
   "metadata": {},
   "source": [
    "#### Step 1A: Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f0a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (4.55.4)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->transformers) (2025.6.15)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
      "\u001b[2K  Attempting uninstall: transformersâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\u001b[33m    WARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[2K    Found existing installation: transformers 4.55.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling transformers-4.55.4:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.55.4â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "optimum-onnx 0.0.3 requires transformers<4.56.0,>=4.36.0, but you have transformers 4.57.1 which is incompatible.\n",
      "fair-llm 0.1.0 requires click==8.2.1, but you have click 8.1.8 which is incompatible.\n",
      "fair-llm 0.1.0 requires huggingface-hub==0.33.0, but you have huggingface-hub 0.35.3 which is incompatible.\n",
      "fair-llm 0.1.0 requires tokenizers==0.21.1, but you have tokenizers 0.22.1 which is incompatible.\n",
      "fair-llm 0.1.0 requires transformers==4.52.4, but you have transformers 4.57.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.22.1 transformers-4.57.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: optimum[onnxruntime] in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.29 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (2.7.1)\n",
      "Requirement already satisfied: packaging in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (25.0)\n",
      "Requirement already satisfied: numpy in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (2.3.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.8.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (0.35.3)\n",
      "Requirement already satisfied: optimum-onnx[onnxruntime] in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum[onnxruntime]) (0.0.3)\n",
      "Requirement already satisfied: filelock in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.8.0->optimum[onnxruntime]) (1.1.4)\n",
      "Requirement already satisfied: setuptools in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11->optimum[onnxruntime]) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers>=4.29->optimum[onnxruntime]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers>=4.29->optimum[onnxruntime]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from transformers>=4.29->optimum[onnxruntime]) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (3.0.2)\n",
      "Collecting transformers>=4.29 (from optimum[onnxruntime])\n",
      "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: onnx in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (1.19.1)\n",
      "Requirement already satisfied: onnxruntime>=1.18.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (1.22.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.29->optimum[onnxruntime])\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: coloredlogs in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (5.29.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.18.0->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (10.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from onnx->optimum-onnx[onnxruntime]; extra == \"onnxruntime\"->optimum[onnxruntime]) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.8.0->optimum[onnxruntime]) (2025.6.15)\n",
      "Using cached transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: transformersâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.12m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.57.1:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.1â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fair-llm 0.1.0 requires click==8.2.1, but you have click 8.1.8 which is incompatible.\n",
      "fair-llm 0.1.0 requires huggingface-hub==0.33.0, but you have huggingface-hub 0.35.3 which is incompatible.\n",
      "fair-llm 0.1.0 requires tokenizers==0.21.1, but you have tokenizers 0.21.4 which is incompatible.\n",
      "fair-llm 0.1.0 requires transformers==4.52.4, but you have transformers 4.55.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.4 transformers-4.55.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchaudio in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyttsx3 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (2.99)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sounddevice\n",
      "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: scipy in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (1.15.3)\n",
      "Collecting CFFI>=1.0 (from sounddevice)\n",
      "  Downloading cffi-2.0.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages (from scipy) (2.3.0)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Downloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
      "Downloading cffi-2.0.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pycparser, CFFI, sounddevice\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [sounddevice]\u001b[0m [CFFI]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed CFFI-2.0.0 pycparser-2.23 sounddevice-0.5.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install optimum[onnxruntime]\n",
    "!pip install torch torchaudio\n",
    "!pip install pyttsx3\n",
    "!pip install sounddevice scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5045455",
   "metadata": {},
   "source": [
    "#### Step 1B: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabfeff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aripontoni/CompSci 471/cs471-pex4/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, torch, torchaudio, re, time, pyttsx3\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from transformers import pipeline, WhisperForConditionalGeneration, AutoProcessor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0c033",
   "metadata": {},
   "source": [
    "#### Step 1C: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be3b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"openai/whisper-tiny.en\"\n",
    "DEVICE = \"cpu\"  # Pi doesn't have GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724ed9a",
   "metadata": {},
   "source": [
    "Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e95d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triage_audio(result, output_dir=\"triage_audio\"):\n",
    "    \"\"\"\n",
    "    Generate audio file from triage results with robust voice handling\n",
    "    \n",
    "    Args:\n",
    "        result: Dictionary containing triage assessment results\n",
    "        output_dir: Directory to save audio files\n",
    "        \n",
    "    Returns:\n",
    "        Path to generated audio or text file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Build the spoken message\n",
    "    message_parts = []\n",
    "    \n",
    "    # Triage category announcement\n",
    "    category = result['triage_category']\n",
    "    message_parts.append(f\"Triage category: {category}.\")\n",
    "    \n",
    "    # Add urgency based on category\n",
    "    if category == \"Immediate\":\n",
    "        message_parts.append(\"This patient requires immediate medical attention.\")\n",
    "    elif category == \"Delayed\":\n",
    "        message_parts.append(\"This patient has serious injuries but can wait for treatment.\")\n",
    "    elif category == \"Minimal\":\n",
    "        message_parts.append(\"This patient has minor injuries.\")\n",
    "    elif category == \"Expectant\":\n",
    "        message_parts.append(\"This patient has injuries incompatible with life.\")\n",
    "    elif category == \"Unknown\":\n",
    "        message_parts.append(\"Additional assessment data needed.\")\n",
    "    \n",
    "    # Confidence level\n",
    "    confidence_pct = int(result['confidence'] * 100)\n",
    "    message_parts.append(f\"Assessment confidence: {confidence_pct} percent.\")\n",
    "    \n",
    "    # Key findings\n",
    "    entities = result['entities']\n",
    "    findings = []\n",
    "    \n",
    "    if entities.get('can_walk') is not None:\n",
    "        findings.append(f\"Patient {'can' if entities['can_walk'] else 'cannot'} walk\")\n",
    "    \n",
    "    if entities.get('bleeding_severe'):\n",
    "        findings.append(\"Severe bleeding detected\")\n",
    "    \n",
    "    if entities.get('resp_rate') is not None:\n",
    "        findings.append(f\"Respiratory rate: {entities['resp_rate']} per minute\")\n",
    "    \n",
    "    if entities.get('obeys_commands') is not None:\n",
    "        findings.append(f\"Patient {'obeys' if entities['obeys_commands'] else 'does not obey'} commands\")\n",
    "    \n",
    "    if findings:\n",
    "        message_parts.append(\"Key findings: \" + \", \".join(findings) + \".\")\n",
    "    \n",
    "    # Next question\n",
    "    if result['next_question']:\n",
    "        message_parts.append(f\"Recommended next question: {result['next_question']}\")\n",
    "    \n",
    "    # Combine all parts\n",
    "    full_message = \" \".join(message_parts)\n",
    "    \n",
    "    # Generate filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    patient_id = result['patient_id'].replace('.mp3', '').replace(' ', '_')\n",
    "    \n",
    "    print(f\"\\nğŸ”Š Generating audio output...\")\n",
    "    print(f\"ğŸ“ Message: {full_message}\")\n",
    "    \n",
    "    # Try to generate audio with pyttsx3\n",
    "    try:\n",
    "        import pyttsx3\n",
    "        engine = pyttsx3.init()\n",
    "        \n",
    "        # Get available voices and use the first one\n",
    "        voices = engine.getProperty('voices')\n",
    "        if voices:\n",
    "            # Use first available voice (usually the system default)\n",
    "            engine.setProperty('voice', voices[0].id)\n",
    "        \n",
    "        # Set properties\n",
    "        engine.setProperty('rate', 150)\n",
    "        engine.setProperty('volume', 0.9)\n",
    "        \n",
    "        output_filename = f\"{output_dir}/triage_{patient_id}_{timestamp}.wav\"\n",
    "        engine.save_to_file(full_message, output_filename)\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        print(f\"âœ“ Audio saved to: {output_filename}\")\n",
    "        return output_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback: Save as text file\n",
    "        print(f\"âš ï¸  Audio generation failed: {e}\")\n",
    "        print(f\"ğŸ’¾ Saving as text file instead...\")\n",
    "        \n",
    "        output_filename = f\"{output_dir}/triage_{patient_id}_{timestamp}.txt\"\n",
    "        with open(output_filename, 'w') as f:\n",
    "            f.write(full_message)\n",
    "        \n",
    "        print(f\"âœ“ Text saved to: {output_filename}\")\n",
    "        print(f\"â„¹ï¸  Audio generation requires proper system audio configuration\")\n",
    "        \n",
    "        return output_filename\n",
    "\n",
    "def generate_quick_alert_audio(category, output_dir=\"triage_audio\"):\n",
    "    \"\"\"\n",
    "    Generate quick alert audio with robust voice handling\n",
    "    \n",
    "    Args:\n",
    "        category: Triage category\n",
    "        output_dir: Directory to save audio files\n",
    "        \n",
    "    Returns:\n",
    "        Path to generated audio or text file\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    alert_messages = {\n",
    "        \"Immediate\": \"Alert! Immediate medical attention required!\",\n",
    "        \"Delayed\": \"Attention. Delayed category patient.\",\n",
    "        \"Minimal\": \"Minimal injuries detected.\",\n",
    "        \"Expectant\": \"Expectant category.\",\n",
    "        \"Unknown\": \"Assessment incomplete.\"\n",
    "    }\n",
    "    \n",
    "    message = alert_messages.get(category, \"Triage assessment complete.\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2bbfd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio_assessment(duration=10, sample_rate=16000, output_dir=\"recordings\"):\n",
    "    \"\"\"\n",
    "    Record audio from microphone for triage assessment\n",
    "    \n",
    "    Args:\n",
    "        duration: Recording duration in seconds (default: 10)\n",
    "        sample_rate: Audio sample rate (default: 16000 for Whisper)\n",
    "        output_dir: Directory to save recordings\n",
    "        \n",
    "    Returns:\n",
    "        Path to recorded audio file\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nğŸ¤ RECORDING TRIAGE ASSESSMENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Duration: {duration} seconds\")\n",
    "    print(f\"Speak clearly and include SALT assessment details:\")\n",
    "    print(f\"  â€¢ Can the patient walk?\")\n",
    "    print(f\"  â€¢ Is there severe bleeding?\")\n",
    "    print(f\"  â€¢ What is the respiratory rate?\")\n",
    "    print(f\"  â€¢ Does the patient obey commands?\")\n",
    "    print(f\"  â€¢ Is there a radial pulse?\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Countdown\n",
    "    for i in range(3, 0, -1):\n",
    "        print(f\"Recording starts in {i}...\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"ğŸ”´ RECORDING NOW - Speak your assessment!\")\n",
    "    \n",
    "    # Record audio\n",
    "    recording = sd.rec(int(duration * sample_rate), \n",
    "                      samplerate=sample_rate, \n",
    "                      channels=1, \n",
    "                      dtype='int16')\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    \n",
    "    print(\"âœ“ Recording complete!\\n\")\n",
    "    \n",
    "    # Save to file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{output_dir}/assessment_{timestamp}.wav\"\n",
    "    write(filename, sample_rate, recording)\n",
    "    \n",
    "    print(f\"ğŸ’¾ Saved to: {filename}\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def interactive_triage_session(sensor_data=None):\n",
    "    \"\"\"\n",
    "    Run an interactive triage session with live recording\n",
    "    \n",
    "    Args:\n",
    "        sensor_data: Optional dict of drone sensor readings\n",
    "        \n",
    "    Returns:\n",
    "        Triage assessment result\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸš INTERACTIVE COMBAT TRIAGE SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nThis system will:\")\n",
    "    print(\"1. Record your verbal patient assessment\")\n",
    "    print(\"2. Transcribe and analyze the information\")\n",
    "    print(\"3. Apply SALT triage protocol\")\n",
    "    print(\"4. Provide triage category and next steps\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Get recording duration from user\n",
    "    try:\n",
    "        duration = int(input(\"\\nHow many seconds do you need? (default: 10): \") or \"10\")\n",
    "    except ValueError:\n",
    "        duration = 10\n",
    "    \n",
    "    # Record audio\n",
    "    audio_file = record_audio_assessment(duration=duration)\n",
    "    \n",
    "    # Process with triage system\n",
    "    print(\"\\nğŸ”„ Processing assessment...\")\n",
    "    result = triage_patient(audio_file, sensor_data=sensor_data, generate_audio=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def continuous_triage_mode(sensor_data=None):\n",
    "    \"\"\"\n",
    "    Continuous triage mode - keeps asking for new assessments\n",
    "    \n",
    "    Args:\n",
    "        sensor_data: Optional dict of drone sensor readings\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ” CONTINUOUS TRIAGE MODE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Press Ctrl+C to exit\\n\")\n",
    "    \n",
    "    patient_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            patient_count += 1\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"PATIENT #{patient_count}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Run triage session\n",
    "            result = interactive_triage_session(sensor_data=sensor_data)\n",
    "            \n",
    "            # Ask if user wants to continue\n",
    "            continue_input = input(\"\\n\\nAssess another patient? (y/n): \").lower()\n",
    "            if continue_input != 'y':\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nâœ“ Triage mode ended\")\n",
    "        print(f\"Total patients assessed: {patient_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767eadc6",
   "metadata": {},
   "source": [
    "## Step 2: Medical Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0360e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded combat medical vocabulary\n",
    "COMBAT_MEDICAL_LEXICON = \"\"\"\n",
    "tourniquet, hemorrhage, massive hemorrhage, capillary refill, \n",
    "obey commands, airway patent, airway obstructed, \n",
    "respirations per minute, respiratory rate, breathing adequately,\n",
    "radial pulse present, radial pulse absent, carotid pulse,\n",
    "shock, hypotensive, pale, clammy, cold,\n",
    "GSW, gunshot wound, blast injury, shrapnel, amputation,\n",
    "conscious, unconscious, alert, verbal, pain, unresponsive,\n",
    "chest seal, needle decompression, nasopharyngeal airway,\n",
    "combat gauze, hemostatic agent, pressure dressing,\n",
    "walking wounded, litter urgent, urgent surgical,\n",
    "can walk, cannot walk, ambulatory, unable to walk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b152e",
   "metadata": {},
   "source": [
    "## Step 3: Model Quantization\n",
    "\n",
    "Useful for the rasberry pi on our drone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739a2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and quantizing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and quantized successfully\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ========== MODEL LOADING WITH QUANTIZATION ==========\n",
    "print(\"Loading and quantizing model...\")\n",
    "\n",
    "# Load model and processor separately\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID)\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Quantize the model (makes it 4x smaller and faster)\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, \n",
    "    {torch.nn.Linear},  # Quantize linear layers\n",
    "    dtype=torch.qint8   # Use 8-bit integers\n",
    ")\n",
    "\n",
    "# Create ASR pipeline with quantized model AND processor components\n",
    "asr = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=quantized_model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    device=DEVICE,\n",
    "    chunk_length_s=30,\n",
    "    stride_length_s=5,\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "print(f\"Model loaded and quantized successfully\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ee3c9",
   "metadata": {},
   "source": [
    "### Step 3: Audio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4342fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combat_audio(audio_path):\n",
    "    \"\"\"Handle noisy battlefield audio conditions\"\"\"\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Resample to 16kHz (Whisper requirement)\n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "    \n",
    "    # Noise reduction - high-pass filter for wind/vehicle noise\n",
    "    wav = torchaudio.functional.highpass_biquad(wav, 16000, cutoff_freq=200)\n",
    "    \n",
    "    # Normalize volume (gunfire may cause clipping)\n",
    "    max_val = wav.abs().max()\n",
    "    if max_val > 0:\n",
    "        wav = wav / max_val\n",
    "    \n",
    "    return wav, 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859fecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_vad_chunks(wav_path, min_speech_len=0.6):\n",
    "    \"\"\"Voice Activity Detection - remove silence\"\"\"\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    \n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "    \n",
    "    # Simple energy-based VAD\n",
    "    energy = wav.pow(2).mean(dim=0)\n",
    "    threshold = energy.mean() * 0.3\n",
    "    \n",
    "    voiced_mask = energy > threshold\n",
    "    if voiced_mask.sum() < 16000 * min_speech_len:\n",
    "        return [wav_path]  # Too short, return original\n",
    "    \n",
    "    # For simplicity, return original if has enough speech\n",
    "    return [wav_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ea1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TRANSCRIPTION ==========\n",
    "def transcribe(path: str) -> dict:\n",
    "    \"\"\"Transcribe audio with medical vocabulary priming\"\"\"\n",
    "    \n",
    "    # Build prompt for medical context\n",
    "    prompt_ids = processor.get_prompt_ids(text=COMBAT_MEDICAL_LEXICON)\n",
    "    \n",
    "    if isinstance(prompt_ids, np.ndarray):\n",
    "        prompt_ids = prompt_ids.tolist()\n",
    "    elif isinstance(prompt_ids, tuple):\n",
    "        prompt_ids = list(prompt_ids)\n",
    "    \n",
    "    prompt_ids = torch.tensor(prompt_ids, dtype=torch.long, device=DEVICE)\n",
    "    \n",
    "    # Clear any old forced decoder IDs\n",
    "    try:\n",
    "        asr.model.generation_config.forced_decoder_ids = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    result = asr(\n",
    "        path,\n",
    "        generate_kwargs={\n",
    "            \"prompt_ids\": prompt_ids,\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_beams\": 5,\n",
    "            \"do_sample\": False,\n",
    "        },\n",
    "        return_timestamps=True\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def transcribe_with_vad(path):\n",
    "    \"\"\"Transcribe with voice activity detection\"\"\"\n",
    "    out = {\"text\": \"\", \"chunks\": []}\n",
    "    \n",
    "    for chunk in simple_vad_chunks(path):\n",
    "        r = transcribe(chunk)\n",
    "        out[\"text\"] += (\" \" + r[\"text\"]).strip()\n",
    "        if \"chunks\" in r:\n",
    "            out[\"chunks\"].extend(r[\"chunks\"])\n",
    "    \n",
    "    return out\n",
    "\n",
    "# ========== ENTITY EXTRACTION ==========\n",
    "def extract_triage_entities(transcription_text):\n",
    "    \"\"\"Extract SALT-relevant medical information from transcription\"\"\"\n",
    "    text_lower = transcription_text.lower()\n",
    "    \n",
    "    entities = {\n",
    "        \"can_walk\": None,\n",
    "        \"bleeding_severe\": False,\n",
    "        \"obeys_commands\": None,\n",
    "        \"resp_rate\": None,\n",
    "        \"radial_pulse\": None,\n",
    "        \"mental_status\": None,\n",
    "        \"cap_refill_sec\": None\n",
    "    }\n",
    "    \n",
    "    evidence = []\n",
    "    \n",
    "    \n",
    "    # Walking ability\n",
    "    walk_yes = [\"can walk\", \"walking\", \"ambulatory\", \"able to walk\"]\n",
    "    walk_no = [\"cannot walk\", \"can't walk\", \"unable to walk\", \"not walking\"]\n",
    "    \n",
    "    for phrase in walk_yes:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"can_walk\"] = True\n",
    "            evidence.append(f\"Walking: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    for phrase in walk_no:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"can_walk\"] = False\n",
    "            evidence.append(f\"Not walking: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Severe bleeding\n",
    "    bleeding_phrases = [\"severe bleeding\", \"hemorrhage\", \"massive hemorrhage\", \n",
    "                       \"tourniquet applied\", \"massive bleeding\", \"heavy bleeding\"]\n",
    "    for phrase in bleeding_phrases:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"bleeding_severe\"] = True\n",
    "            evidence.append(f\"Severe bleeding: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Command response\n",
    "    obey_yes = [\"obeys commands\", \"follows commands\", \"responsive to commands\", \"responding\"]\n",
    "    obey_no = [\"does not obey\", \"doesn't obey\", \"unresponsive\", \"no response\", \n",
    "               \"not responding\", \"not obeying\"]\n",
    "    \n",
    "    for phrase in obey_yes:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"obeys_commands\"] = True\n",
    "            evidence.append(f\"Obeys commands: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    for phrase in obey_no:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"obeys_commands\"] = False\n",
    "            evidence.append(f\"Does not obey: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Respiratory rate extraction\n",
    "    resp_patterns = [\n",
    "        r'(\\d+)\\s*breaths?\\s*(?:per\\s*minute)?',\n",
    "        r'(\\d+)\\s*respirations?\\s*(?:per\\s*minute)?',\n",
    "        r'respiratory\\s*rate\\s*(?:of\\s*)?(\\d+)',\n",
    "        r'breathing\\s*(?:at\\s*)?(\\d+)',\n",
    "        r'(\\d+)\\s*rpm'\n",
    "    ]\n",
    "    \n",
    "    for pattern in resp_patterns:\n",
    "        match = re.search(pattern, text_lower)\n",
    "        if match:\n",
    "            entities[\"resp_rate\"] = int(match.group(1))\n",
    "            evidence.append(f\"Respiratory rate: {match.group(1)} detected\")\n",
    "            break\n",
    "    \n",
    "    # Radial pulse\n",
    "    pulse_yes = [\"radial pulse present\", \"has radial pulse\", \"pulse present\"]\n",
    "    pulse_no = [\"no radial pulse\", \"radial pulse absent\", \"no pulse\"]\n",
    "    \n",
    "    for phrase in pulse_yes:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"radial_pulse\"] = True\n",
    "            evidence.append(f\"Radial pulse: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    for phrase in pulse_no:\n",
    "        if phrase in text_lower:\n",
    "            entities[\"radial_pulse\"] = False\n",
    "            evidence.append(f\"No radial pulse: '{phrase}' detected\")\n",
    "            break\n",
    "    \n",
    "    # Mental status\n",
    "    if \"alert\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"alert\"\n",
    "        evidence.append(\"Mental status: alert\")\n",
    "    elif \"verbal\" in text_lower or \"responds to verbal\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"verbal\"\n",
    "        evidence.append(\"Mental status: verbal\")\n",
    "    elif \"pain\" in text_lower or \"responds to pain\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"pain\"\n",
    "        evidence.append(\"Mental status: pain\")\n",
    "    elif \"unresponsive\" in text_lower:\n",
    "        entities[\"mental_status\"] = \"unresponsive\"\n",
    "        evidence.append(\"Mental status: unresponsive\")\n",
    "    \n",
    "    return entities, evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d27d05e",
   "metadata": {},
   "source": [
    "## Step 5: Implement SALT Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a22e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SALT TRIAGE RULES ==========\n",
    "def salt_rules(entities, sensors=None):\n",
    "    \"\"\"\n",
    "    Implement SALT (Sort, Assess, Lifesaving interventions, Treatment/Transport) triage\n",
    "    \n",
    "    Categories:\n",
    "    - Immediate (Red): Life-threatening injuries, needs immediate care\n",
    "    - Delayed (Yellow): Serious injuries, can wait for treatment\n",
    "    - Minimal (Green): Minor injuries, walking wounded\n",
    "    - Expectant (Black): Injuries incompatible with life\n",
    "    \"\"\"\n",
    "    s = sensors or {}\n",
    "    \n",
    "    # Merge sensor data\n",
    "    can_walk = entities.get(\"can_walk\") or s.get(\"can_walk\")\n",
    "    severe_bleed = entities.get(\"bleeding_severe\") or s.get(\"bleeding_detected\")\n",
    "    resp = entities.get(\"resp_rate\") or s.get(\"resp_rate\")\n",
    "    obeys = entities.get(\"obeys_commands\") or s.get(\"obeys_commands\")\n",
    "    radial_pulse = entities.get(\"radial_pulse\") or s.get(\"radial_pulse\")\n",
    "    \n",
    "    # SALT Algorithm\n",
    "    # Step 1: Can the patient walk?\n",
    "    if can_walk is True:\n",
    "        return \"Minimal\"\n",
    "    \n",
    "    # Step 2: Assess for life-threatening bleeding\n",
    "    if severe_bleed:\n",
    "        return \"Immediate\"\n",
    "    \n",
    "    # Step 3: Check respirations\n",
    "    if resp is None:\n",
    "        return \"Unknown\"  # Need more data\n",
    "    \n",
    "    if resp == 0:\n",
    "        return \"Expectant\"  # Not breathing\n",
    "    \n",
    "    if resp >= 30:\n",
    "        return \"Immediate\"  # Respiratory distress\n",
    "    \n",
    "    # Step 4: Check mental status / obeys commands\n",
    "    if obeys is False:\n",
    "        return \"Immediate\"  # Altered mental status\n",
    "    \n",
    "    # Step 5: Check radial pulse (perfusion)\n",
    "    if radial_pulse is False:\n",
    "        return \"Immediate\"  # Poor perfusion\n",
    "    \n",
    "    # Default: injuries present but stable\n",
    "    return \"Delayed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ddc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIDENCE & NEXT QUESTION ==========\n",
    "def calculate_confidence(entities):\n",
    "    \"\"\"Calculate confidence based on how much data we have\"\"\"\n",
    "    total_fields = len(entities)\n",
    "    filled_fields = sum(1 for v in entities.values() if v is not None and v is not False)\n",
    "    return filled_fields / total_fields\n",
    "\n",
    "def suggest_next_question(entities):\n",
    "    \"\"\"Ask medic for missing critical SALT info\"\"\"\n",
    "    \n",
    "    if entities[\"can_walk\"] is None:\n",
    "        return \"Can the patient walk?\"\n",
    "    \n",
    "    if not entities[\"bleeding_severe\"] and entities.get(\"bleeding_severe\") is None:\n",
    "        return \"Is there severe bleeding or hemorrhage?\"\n",
    "    \n",
    "    if entities[\"resp_rate\"] is None:\n",
    "        return \"What is the respiratory rate per minute?\"\n",
    "    \n",
    "    if entities[\"obeys_commands\"] is None:\n",
    "        return \"Does the patient obey commands?\"\n",
    "    \n",
    "    if entities[\"radial_pulse\"] is None:\n",
    "        return \"Is there a radial pulse present?\"\n",
    "    \n",
    "    return None  # All critical data collected\n",
    "\n",
    "# ========== SENSOR FUSION ==========\n",
    "def fuse_sensor_data(audio_entities, drone_sensors):\n",
    "    \"\"\"Combine voice transcription with drone sensor data\"\"\"\n",
    "    final_entities = audio_entities.copy()\n",
    "    \n",
    "    # Sensor data overrides uncertain voice data\n",
    "    if drone_sensors.get(\"thermal_bleeding_detected\") is not None:\n",
    "        if audio_entities[\"bleeding_severe\"] is None or not audio_entities[\"bleeding_severe\"]:\n",
    "            final_entities[\"bleeding_severe\"] = drone_sensors[\"thermal_bleeding_detected\"]\n",
    "    \n",
    "    if drone_sensors.get(\"movement_detected\") is not None:\n",
    "        if audio_entities[\"can_walk\"] is None:\n",
    "            final_entities[\"can_walk\"] = drone_sensors[\"movement_detected\"]\n",
    "    \n",
    "    if drone_sensors.get(\"heart_rate\") is not None:\n",
    "        # Estimate respiratory rate from heart rate if not available\n",
    "        if audio_entities[\"resp_rate\"] is None:\n",
    "            # Rough estimate: normal resp is ~1/4 of heart rate\n",
    "            final_entities[\"resp_rate\"] = int(drone_sensors[\"heart_rate\"] / 4)\n",
    "    \n",
    "    return final_entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af81fc",
   "metadata": {},
   "source": [
    "## Step 6: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca6bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_patient(audio_path, sensor_data=None, generate_audio=True):\n",
    "    \"\"\"\n",
    "    Complete combat triage pipeline with optional audio output\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to audio file of medic assessment\n",
    "        sensor_data: Optional dict of drone sensor readings\n",
    "        generate_audio: Whether to generate audio output (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        Full triage assessment with category and confidence\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRIAGE ASSESSMENT INITIATED\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Step 1: Transcribe audio\n",
    "    print(\"ğŸ“ Transcribing audio...\")\n",
    "    transcription = transcribe_with_vad(audio_path)\n",
    "    print(f\"âœ“ Transcription: {transcription['text'][:100]}...\")\n",
    "    \n",
    "    # Step 2: Extract medical entities\n",
    "    print(\"\\nğŸ” Extracting medical information...\")\n",
    "    entities, evidence = extract_triage_entities(transcription[\"text\"])\n",
    "    \n",
    "    # Step 3: Fuse with sensor data if available\n",
    "    if sensor_data:\n",
    "        print(\"ğŸ¤– Fusing with sensor data...\")\n",
    "        entities = fuse_sensor_data(entities, sensor_data)\n",
    "    \n",
    "    # Step 4: Apply SALT triage rules\n",
    "    print(\"\\nğŸ¥ Applying SALT triage protocol...\")\n",
    "    triage_category = salt_rules(entities, sensor_data)\n",
    "    \n",
    "    # Step 5: Calculate confidence and suggest next question\n",
    "    confidence = calculate_confidence(entities)\n",
    "    next_question = suggest_next_question(entities)\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Format results\n",
    "    result = {\n",
    "        \"patient_id\": os.path.basename(audio_path),\n",
    "        \"transcription\": transcription[\"text\"],\n",
    "        \"entities\": entities,\n",
    "        \"evidence\": evidence,\n",
    "        \"triage_category\": triage_category,\n",
    "        \"confidence\": confidence,\n",
    "        \"next_question\": next_question,\n",
    "        \"processing_time_sec\": round(processing_time, 2),\n",
    "        \"timestamp\": transcription.get(\"chunks\", [])\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRIAGE RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ğŸš‘ Category: {triage_category}\")\n",
    "    print(f\"ğŸ“Š Confidence: {confidence*100:.0f}%\")\n",
    "    print(f\"â±ï¸  Processing Time: {processing_time:.2f}s\")\n",
    "    print(f\"\\nğŸ“‹ Extracted Information:\")\n",
    "    for key, value in entities.items():\n",
    "        if value is not None:\n",
    "            print(f\"  â€¢ {key}: {value}\")\n",
    "    \n",
    "    if next_question:\n",
    "        print(f\"\\nâ“ Recommended Question: {next_question}\")\n",
    "    \n",
    "    if evidence:\n",
    "        print(f\"\\nğŸ“ Evidence:\")\n",
    "        for item in evidence:\n",
    "            print(f\"  â€¢ {item}\")\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # NEW: Generate audio output\n",
    "    if generate_audio:\n",
    "        audio_file = generate_triage_audio(result)\n",
    "        result['audio_output'] = audio_file\n",
    "        \n",
    "        # Generate quick alert for immediate cases\n",
    "        if triage_category == \"Immediate\":\n",
    "            alert_file = generate_quick_alert_audio(triage_category)\n",
    "            result['alert_audio'] = alert_file\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f61c8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRIAGE SYSTEM READY\n",
      "============================================================\n",
      "\n",
      "Choose a mode:\n",
      "1. Single interactive assessment (with recording)\n",
      "2. Continuous triage mode (multiple patients)\n",
      "3. Test with existing audio file\n",
      "============================================================\n",
      "Invalid mode selected\n"
     ]
    }
   ],
   "source": [
    "# Test with audio generation\n",
    "\n",
    "# ========== INTERACTIVE TESTING OPTIONS ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRIAGE SYSTEM READY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nChoose a mode:\")\n",
    "print(\"1. Single interactive assessment (with recording)\")\n",
    "print(\"2. Continuous triage mode (multiple patients)\")\n",
    "print(\"3. Test with existing audio file\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mode = input(\"\\nEnter mode (1/2/3): \").strip()\n",
    "\n",
    "if mode == \"1\":\n",
    "    # Single interactive session\n",
    "    result = interactive_triage_session()\n",
    "    \n",
    "elif mode == \"2\":\n",
    "    # Continuous mode\n",
    "    continuous_triage_mode()\n",
    "    \n",
    "elif mode == \"3\":\n",
    "    # Test with existing file\n",
    "    AUDIO = input(\"Enter audio file path: \").strip() or \"EnglishTriageTest 1.mp3\"\n",
    "    \n",
    "    print(\"\\nTEST 1: Audio transcription with audio output\")\n",
    "    result1 = triage_patient(AUDIO, generate_audio=True)\n",
    "    \n",
    "    print(\"\\n\\nTEST 2: Audio + sensor fusion with audio output\")\n",
    "    mock_sensor_data = {\n",
    "        \"thermal_bleeding_detected\": False,\n",
    "        \"movement_detected\": False,\n",
    "        \"heart_rate\": 120\n",
    "    }\n",
    "    result2 = triage_patient(AUDIO, sensor_data=mock_sensor_data, generate_audio=True)\n",
    "else:\n",
    "    print(\"Invalid mode selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece06fb",
   "metadata": {},
   "source": [
    "## Step 7: Performance metrics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88117c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE METRICS\n",
      "============================================================\n",
      "Model: openai/whisper-tiny.en\n",
      "Quantized: Yes (8-bit)\n",
      "Device: cpu\n",
      "Model parameters: 21.2M\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== PERFORMANCE METRICS ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"Quantized: Yes (8-bit)\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in asr.model.parameters()) / 1e6:.1f}M\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
